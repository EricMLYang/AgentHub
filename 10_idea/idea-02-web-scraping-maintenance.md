# [Idea] 爬蟲維運 Agent

## 😫 痛點（現在多煩）

網站爬蟲經常因為目標網站改版而失效：
- 需要人工監控數據品質與抓取狀態
- 網站 DOM/CSS 變更後 selector 失效，需要手動修復
- 難以提前發現結構性變更
- 修復時間長，影響數據時效性
- 缺乏系統化的維運機制

## 👤 目標使用者（誰會用）

- 數據工程師：負責維護爬蟲系統
- 數據分析師：依賴爬蟲數據做分析
- 業務團隊：需要穩定的數據來源

## 📥 輸入（Input）

- 現有爬蟲程式碼（selector / XPath）
- 目標網站 URL
- 歷史 DOM 結構 snapshot
- 歷史抓取數據（用於比對品質）
- 資料品質檢查規則
- 爬蟲執行 log

## 📤 輸出（Output）

- **異常偵測告警**（資料缺失/結構變動）
- **CSS/DOM 變更報告**（比對歷史差異）
- **修正建議**（更新後的 Selector/XPath）
- **重構建議文件**（當變更過大時）
- 自動開 PR（修復 patch）

## ✅ 驗收方式（Acceptance Criteria）

- [ ] 資料缺失或品質下降時 5 分鐘內發送告警
- [ ] DOM 結構變更時能準確定位變更位置
- [ ] 修復建議在 sandbox 環境測試通過
- [ ] 修復後資料分布與歷史一致（抽樣比對）
- [ ] 自動開 PR，但需要人工 review 才能 merge（HITL）
- [ ] Golden pages 測試通過（關鍵頁面驗證）
- [ ] 誤報率 < 10%

## ⚠️ 風險/限制

- **默默抓錯最危險**：資料看起來正常但實際錯誤 → 必須有資料分布校驗、抽樣人工 spot-check、對帳機制
- 網站可能有反爬機制（IP 封鎖、驗證碼）
- 大規模網站改版可能需要完全重寫爬蟲邏輯
- 需要歷史 DOM 資料作為比對基準

## 💭 其他補充

**Agent 化適配評分（1-5）**：
- 規則明確性：3（偵測清楚，修復不一定）
- 可驗證性：4（修復後能否成功抓到資料＝立即驗證）
- 回饋延遲：5（秒級抓一次就知道）
- 資料可得性：4（DOM 差異、歷史 selector、log）
- KPI：4（修復時間、失敗次數、人工介入率）
- 風險：3（錯抓資料風險，中等）
- **總評：4/5（很像程式任務，閉環強）**

**選型建議**：Traditional code + Workflow 為底；Agent 用於「修復建議生成」
- 偵測（缺失率、欄位空值、DOM hash 變動）是規則型：用 code 最可靠
- 真的難的是「網站改版後 selector 怎麼修」→ 這段才值得 Agent/LLM

**7 類型定位**：Business-task Agent（監控告警）+ Developer Agent（產修復 patch）

**驗證閉環**：sandbox 抓取測試、golden pages、抽樣比對（內容分布/欄位 regex）
